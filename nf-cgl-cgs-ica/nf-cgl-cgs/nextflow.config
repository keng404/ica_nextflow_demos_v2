/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Clinical-Genomics-Laboratory/nf-cgl-cgs Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {

    // Input options
    input                             = null
    batch_name                        = null
    fastq_list                        = null
    sample_info                       = null
    illumina_rundir                   = null
    transfer_data                     = true

    // Output options
    outdir                            = null
    qc_outdir                         = '/storage1/fs1/gtac-mgi/Active/CLE/assay/CGS/batchdir'
    demux_outdir                      = '/storage1/fs1/gtac-mgi/Active/CLE/assay/CGS/demux_fastq'

    // LSF cluster options
    host                              = "compute1-exec-235"
    queue                             = 'pathology'
    user_group                        = 'compute-gtac-mgi'
    job_group_name                    = null

    // DRAGEN alignment options
    create_gvcf                       = true
    refdir                            = '/storage1/fs1/duncavagee/Active/SEQ/reference/dragen_hg38_multigenome_v4.3.6'
    dbsnp                             = '/storage1/fs1/duncavagee/Active/SEQ/reference/dragen_align_inputs/hg38/dbsnp.vcf.gz'
    adapter1                          = '/storage1/fs1/duncavagee/Active/SEQ/reference/dragen_align_inputs/hg38/dragen_adapter1.fa'
    adapter2                          = '/storage1/fs1/duncavagee/Active/SEQ/reference/dragen_align_inputs/hg38/dragen_adapter2.fa'
    intermediate_dir                  = '/staging/intermediate-results-dir'
    qc_coverage_region                = '/storage1/fs1/duncavagee/Active/SEQ/reference/qc_regions/hglft_genome_bbd5_b7c870_hg38.bed'
    qc_cross_contamination            = '/opt/dragen/4.3.6/resources/qc/sample_cross_contamination_resource_hg38.vcf.gz'

    // DRAGEN joint genotype options
    joint_genotype_sv                 = false
    joint_genotype_cnv                = false
    joint_genotype_small_variants     = true

    // References
    genome                      = null
    igenomes_base               = 's3://ngi-igenomes/igenomes/'
    igenomes_ignore             = true
    fasta                       = null

    // MultiQC options
    multiqc_config              = null
    multiqc_title               = null
    multiqc_logo                = null
    max_multiqc_email_size      = '25.MB'
    multiqc_methods_description = null

    // Boilerplate options
    publish_dir_mode             = 'copy'
    email                        = null
    email_on_fail                = null
    plaintext_email              = false
    monochrome_logs              = false
    hook_url                     = null
    help                         = false
    version                      = false
    pipelines_testdata_base_path = 'https://raw.githubusercontent.com/nf-core/test-datasets/'
    monochromeLogs               = null // TODO remove when nf-core fixes nf-validation bug

    // Config options
    config_profile_name          = null
    config_profile_description   = null
    custom_config_version        = 'master'
    custom_config_base           = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
    config_profile_contact       = null
    config_profile_url           = null

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                   = '128.GB'
    max_cpus                     = 16
    max_time                     = '240.h'

    // Schema validation default options
    validationFailUnrecognisedParams = false
    validationLenientMode            = false
    validationSchemaIgnoreParams     = 'genomes,igenomes_base,monochromeLogs'
    validationShowHiddenParams       = false
    validate_params                  = true

}

// Check LSF job submission parameters
def lsf_host       = params.host           ? "-m ${params.host}"           : ""
def lsf_queue      = params.queue          ? "-q ${params.queue}"          : ""
def lsf_user_group = params.user_group     ? "-G ${params.user_group}"     : ""
def lsf_group_name = params.job_group_name ? "-g ${params.job_group_name}" : ""

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

// Load Clinical-Genomics-Laboratory/nf-cgl-cgs custom profiles from different institutions.
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config/nf-cgl-cgs profiles: ${params.custom_config_base}/nfcore_custom.config")
}
profiles {
    debug {
        dumpHashes              = true
        process.beforeScript    = 'echo $HOSTNAME'
        cleanup                 = false
        nextflow.enable.configProcessNamesValidation = true
    }
    conda {
        conda.enabled           = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        conda.channels          = ['conda-forge', 'bioconda', 'defaults']
        apptainer.enabled       = false
    }
    mamba {
        conda.enabled           = true
        conda.useMamba          = true
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
        docker.runOptions       = '-u $(id -u):$(id -g)'
    }
    arm {
        docker.runOptions       = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled     = true
        singularity.autoMounts  = true
        conda.enabled           = false
        docker.enabled          = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    podman {
        podman.enabled          = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        shifter.enabled         = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    shifter {
        shifter.enabled         = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        charliecloud.enabled    = false
        apptainer.enabled       = false
    }
    charliecloud {
        charliecloud.enabled    = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        apptainer.enabled       = false
    }
    apptainer {
        apptainer.enabled       = true
        apptainer.autoMounts    = true
        conda.enabled           = false
        docker.enabled          = false
        singularity.enabled     = false
        podman.enabled          = false
        shifter.enabled         = false
        charliecloud.enabled    = false
    }
    wave {
        apptainer.ociAutoPull   = true
        singularity.ociAutoPull = true
        wave.enabled            = true
        wave.freeze             = true
        wave.strategy           = 'conda,container'
    }
    gitpod {
        executor.name           = 'local'
        executor.cpus           = 4
        executor.memory         = 8.GB
    }
    ris {
        executor.queueSize       = 20
        executor.submitRateLimit = '1/1sec'
        process {
            executor             = "lsf"
            clusterOptions       =   { "-sp 100 -a 'docker(${task.container})' ${lsf_host} ${lsf_queue} ${lsf_user_group} ${lsf_group_name}" }
        }
    }
    dragen2 {
        process {
            withLabel:dragen {
                queue          = { "dragen-2" }
                memory         = 200.GB
                cpus           = 20
                time           = 16.h
                clusterOptions = { "-sp 100 -a 'gtac-mgi-dragen(${task.container})' -m compute1-dragen-2 ${lsf_user_group} ${lsf_group_name} -env 'all, LSF_DOCKER_DRAGEN=y'" }
            }
        }
    }
    dragen4 {
        process {
            withLabel:dragen {
                queue          = { "dragen-4" }
                memory         = 200.GB
                cpus           = 30
                time           = 16.h
                clusterOptions = { "-sp 100 -a 'gtac-mgi-dragen(${task.container})' -m compute1-dragen-4 ${lsf_user_group} ${lsf_group_name} -env 'all, LSF_DOCKER_DRAGEN=y'" }
            }
        }
    }
    dragen5 {
        process {
            withLabel:dragen {
                queue          = { "dragen-5" }
                memory         = 200.GB
                cpus           = 30
                time           = 16.h
                clusterOptions = { "-sp 100 -a 'gtac-mgi-dragen(${task.container})' -m compute1-dragen-5 ${lsf_user_group} ${lsf_group_name} -env 'all, LSF_DOCKER_DRAGEN=y'" }
            }
        }
    }
    dragenaws {
        process {
            withLabel:dragen {
                executor                = 'awsbatch'
                ext.dragen_license_args = "--lic-server 'https://${secrets.AWS_DRAGEN_USER}:${secrets.AWS_DRAGEN_PASSWORD}@license.edicogenome.com'"
                queue                   = 'nextflow-dragen-aws-queue'
                containerOptions        = '--privileged --ulimit nofile=65535:65535 --ulimit nproc=16384:16384'
                maxErrors               = 1
                cpus                    = 15
                memory                  = 220.GB
                time                    = 16.h
            }
        }
        aws {
            region      = 'us-east-1'
            batch {
                cliPath = '/home/centos/miniconda/bin/aws'
                volumes = '/dev/shm:/dev/shm'
            }
            accessKey   = secrets.AWS_ACCESS_KEY
            secretKey   = secrets.AWS_SECRET_KEY
        }
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
}

// Set default registry for Apptainer, Docker, Podman and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry   = 'quay.io'
docker.registry      = 'quay.io'
podman.registry      = 'quay.io'
singularity.registry = 'quay.io'

// Nextflow plugins
plugins {
    id 'nf-validation@1.1.3' // Validation of pipeline parameters and creation of an input channel from a sample sheet
    id 'nf-amazon'
}

// Load igenomes.config if required
if (!params.igenomes_ignore) {
    includeConfig 'conf/igenomes.config'
} else {
    params.genomes = [:]
}
// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Disable process selector warnings by default. Use debug profile to enable warnings.
nextflow.enable.configProcessNamesValidation = false

def trace_timestamp = new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'Clinical-Genomics-Laboratory/nf-cgl-cgs'
    author          = """Clinical-Genomics-Laboratory"""
    homePage        = 'https://github.com/Clinical-Genomics-Laboratory/nf-cgl-cgs'
    description     = """Analysis pipeline for constitutional Genome Sequences (cGS)."""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.04.0'
    version         = '1.0dev'
    doi             = ''
}

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

/*
 * -------------------------------------------------
 *  nf-core/hic Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

// Global default params, used in configs
params {
  // Inputs / outputs
  genome = false
  input = null
  input_paths = null
  outdir = './results'
  genome = false
  input_paths = false
  chromosome_size = false
  restriction_fragments = false
  save_reference = false
 
  // Mapping
  split_fastq = false
  fastq_chunks_size = 20000000
  save_interaction_bam = false
  save_aligned_intermediates = false
  bwt2_opts_end2end = '--very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder'
  bwt2_opts_trimmed = '--very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder'
  keep_dups = false
  keep_multi = false
  min_mapq = 10


  // Digestion Hi-C
  digestion = false
  digest {
    'hindiii'{
       restriction_site='A^AGCTT'
       ligation_site='AAGCTAGCTT'
    }
    'mboi' {
       restriction_site='^GATC'
       ligation_site='GATCGATC'
    }
    'dpnii' {
       restriction_site='^GATC'
       ligation_site='GATCGATC'
    }
    'arima' {
       restriction_site='^GATC,G^ANT'
       ligation_site='GATCGATC,GATCGANT,GANTGATC,GANTGANT'
    }
  }
  min_restriction_fragment_size = 0
  max_restriction_fragment_size = 0
  min_insert_size = 0
  max_insert_size = 0
  save_nonvalid_pairs = false

  // Dnase Hi-C
  dnase = false
  min_cis_dist = 0

  // Contact maps
  bin_size = '1000000'
  res_zoomify = '5000'
  hicpro_maps = false
  ice_max_iter = 100
  ice_filter_low_count_perc = 0.02
  ice_filter_high_count_perc =  0
  ice_eps = 0.1

  // Downstream Analysis
  res_dist_decay = '250000'
  tads_caller = 'insulation'
  res_tads = '40000'
  res_compartments = '250000'

  // Workflow
  skip_maps = false
  skip_balancing = false
  skip_mcool = false
  skip_dist_decay = false
  skip_compartments = false
  skip_tads = false
  skip_multiqc = false
  
  // Boilerplate options
  publish_dir_mode = 'copy'
  multiqc_config = false
  email = false
  email_on_fail = false
  max_multiqc_email_size = 25.MB
  plaintext_email = false
  monochrome_logs = false
  help = false
  igenomes_base = 's3://ngi-igenomes/igenomes'
  tracedir = "${params.outdir}/pipeline_info"
  igenomes_ignore = false

  //Config
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames = false
  config_profile_name = null
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false
  validate_params = true
  show_hidden_params = false
  schema_ignore_params = 'genomes,digest,input_paths'

  // Defaults only, expecting to be overwritten
  max_memory = 24.GB
  max_cpus = 8
  max_time = 240.h
}

// Container slug. Stable releases should specify release tag!
// Developmental code should specify :dev
process.container = 'nfcore/hic:1.3.0'

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load nf-core custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

// Create profiles
profiles {
  conda {
    docker.enabled = false
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    process.conda = "$projectDir/environment.yml"
  }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker {
    docker.enabled = true
    singularity.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    // Avoid this error:
    //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
    // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
    // once this is established and works well, nextflow might implement this behavior as new default.
    docker.runOptions = '-u \$(id -u):\$(id -g)'
  }
  singularity {
    docker.enabled = false
    singularity.enabled = true
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = false
    singularity.autoMounts = true
  }
  podman {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = true
    shifter.enabled = false
    charliecloud.enabled = false
  }
  shifter {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = true
    charliecloud.enabled = false
  }
  charliecloud {
    singularity.enabled = false
    docker.enabled = false
    podman.enabled = false
    shifter.enabled = false
    charliecloud.enabled = true
  }
  test { includeConfig 'conf/test.config' }
  test_full { includeConfig 'conf/test_full.config' }
}

// Load igenomes.config if required
if (!params.igenomes_ignore) {
  includeConfig 'conf/igenomes.config'
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}

manifest {
  name = 'nf-core/hic'
  author = 'Nicolas Servant'
  homePage = 'https://github.com/nf-core/hic'
  description = 'Analysis of Chromosome Conformation Capture data (Hi-C)'
  mainScript = 'main.nf'
  nextflowVersion = '>=20.04.0'
  version = '1.3.0'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}